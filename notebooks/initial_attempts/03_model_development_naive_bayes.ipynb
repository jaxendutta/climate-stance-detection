{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Stance Detection using Naive Bayes (NaN Handling)\n",
    "\n",
    "This notebook implements a simple, resource-efficient approach to stance detection using Multinomial Naive Bayes and TF-IDF features, with proper handling of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 6449, Test data: 1613\n",
      "Stance labels: [2 0 1]\n",
      "\n",
      "Sample data from training set:\n",
      "                                      processed_text  stance\n",
      "0           worst hurrican season evar accord expert       2\n",
      "1                demand climat action finnish govern       0\n",
      "2       home depot fine million sell ban superpollut       2\n",
      "3  mexiko illegal abholz vertreibt ureinwohn orga...       2\n",
      "4  web mobil dev look help hey web dev realli wan...       0\n",
      "\n",
      "Class distribution in training set:\n",
      "stance\n",
      "2    0.889750\n",
      "0    0.105288\n",
      "1    0.004962\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "NaN values in training set:\n",
      "id                   0\n",
      "title                0\n",
      "body              4992\n",
      "score                0\n",
      "num_comments         0\n",
      "created_utc          0\n",
      "language             0\n",
      "subreddit            0\n",
      "text                 0\n",
      "processed_text       0\n",
      "stance               0\n",
      "dtype: int64\n",
      "\n",
      "NaN values in test set:\n",
      "id                   0\n",
      "title                0\n",
      "body              1228\n",
      "score                0\n",
      "num_comments         0\n",
      "created_utc          0\n",
      "language             0\n",
      "subreddit            0\n",
      "text                 0\n",
      "processed_text       0\n",
      "stance               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "train_data = pd.read_csv('../data/processed/train.csv')\n",
    "val_data = pd.read_csv('../data/processed/val.csv')\n",
    "test_data = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "# Combine train and validation data\n",
    "all_train_data = pd.concat([train_data, val_data], ignore_index=True)\n",
    "\n",
    "# Remove rows with NaN values\n",
    "all_train_data = all_train_data.dropna(subset=['processed_text', 'stance'])\n",
    "test_data = test_data.dropna(subset=['processed_text', 'stance'])\n",
    "\n",
    "print(f\"Training data: {len(all_train_data)}, Test data: {len(test_data)}\")\n",
    "print(f\"Stance labels: {all_train_data['stance'].unique()}\")\n",
    "\n",
    "# Display some sample data\n",
    "print(\"\\nSample data from training set:\")\n",
    "print(all_train_data[['processed_text', 'stance']].head())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(all_train_data['stance'].value_counts(normalize=True))\n",
    "\n",
    "# Check for any remaining NaN values\n",
    "print(\"\\nNaN values in training set:\")\n",
    "print(all_train_data.isna().sum())\n",
    "print(\"\\nNaN values in test set:\")\n",
    "print(test_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed.\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with TF-IDF vectorizer and Multinomial Naive Bayes classifier\n",
    "stance_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "stance_classifier.fit(all_train_data['processed_text'], all_train_data['stance'])\n",
    "\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Save the model\n",
    "import os\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(stance_classifier, '../models/naive_bayes_stance_classifier.joblib')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.39      0.55       190\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.92      0.99      0.95      1410\n",
      "\n",
      "    accuracy                           0.92      1613\n",
      "   macro avg       0.61      0.46      0.50      1613\n",
      "weighted avg       0.91      0.92      0.90      1613\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u1/a9dutta/miniconda3/envs/my_jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/u1/a9dutta/miniconda3/envs/my_jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/u1/a9dutta/miniconda3/envs/my_jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = stance_classifier.predict(test_data['processed_text'])\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(test_data['stance'], y_pred)\n",
    "print(\"Model Evaluation Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results and Next Steps\n",
    "\n",
    "Based on the evaluation results, let's analyze the model's performance:\n",
    "\n",
    "1. Overall accuracy: \n",
    "   The model achieves an overall accuracy of 92%, which seems high at first glance. However, this high accuracy is misleading due to class imbalance.\n",
    "\n",
    "2. Performance across different stances:\n",
    "   - Class 0 (presumably \"Against\"): Precision is high (90%), but recall is low (39%), resulting in an F1-score of 0.55.\n",
    "   - Class 1 (presumably \"Neutral\"): The model completely fails to predict this class (0% for all metrics).\n",
    "   - Class 2 (presumably \"For\"): High performance across all metrics (precision: 92%, recall: 99%, F1-score: 0.95).\n",
    "\n",
    "3. Class imbalance:\n",
    "   There's a severe class imbalance in the dataset. Out of 1613 samples:\n",
    "   - Class 0: 190 samples\n",
    "   - Class 1: 13 samples\n",
    "   - Class 2: 1410 samples\n",
    "\n",
    "4. Model limitations:\n",
    "   - The model is unable to identify the minority class (Class 1, likely \"Neutral\" stance).\n",
    "   - It has a tendency to overpredict the majority class (Class 2, likely \"For\" stance).\n",
    "\n",
    "Next steps:\n",
    "\n",
    "1. Address class imbalance:\n",
    "   - Use techniques like oversampling (e.g., SMOTE), undersampling, or a combination of both.\n",
    "   - Adjust class weights in the classifier to give more importance to minority classes.\n",
    "\n",
    "2. Feature engineering:\n",
    "   - Experiment with different feature extraction methods (e.g., word embeddings like Word2Vec or GloVe).\n",
    "   - Try different n-gram ranges or increase the number of features in TfidfVectorizer.\n",
    "\n",
    "3. Try other classifiers:\n",
    "   - Logistic Regression with balanced class weights\n",
    "   - Support Vector Machines (SVM) with class weight adjustment\n",
    "   - Random Forest or Gradient Boosting classifiers, which can handle imbalanced datasets better\n",
    "\n",
    "4. Ensemble methods:\n",
    "   - Implement voting classifiers or stacking with multiple base models\n",
    "\n",
    "5. Error analysis:\n",
    "   - Examine misclassified samples, especially for classes 0 and 1, to understand where the model is failing\n",
    "\n",
    "6. Data augmentation:\n",
    "   - For the minority classes, consider techniques like back-translation or synonym replacement to create more samples\n",
    "\n",
    "7. Revisit preprocessing:\n",
    "   - Ensure that the preprocessing steps are not inadvertently removing important information, especially for the minority classes\n",
    "\n",
    "8. Consider using a small, lightweight version of a transformer model:\n",
    "   - While full-scale transformers were too memory-intensive, a small version like DistilBERT or a lightweight BERT might work and could potentially handle the imbalance better\n",
    "\n",
    "Implementation plan:\n",
    "1. Start by addressing the class imbalance through resampling techniques and class weight adjustments.\n",
    "2. If performance is still unsatisfactory, experiment with different classifiers, focusing on those that handle imbalanced data well.\n",
    "3. Conduct thorough error analysis to gain insights into the model's weaknesses.\n",
    "4. Based on the error analysis, refine feature engineering and potentially revisit the preprocessing steps.\n",
    "5. If these steps don't yield satisfactory results, consider implementing a lightweight transformer model or an ensemble method.\n",
    "\n",
    "Remember, for a stance detection task, it's crucial to have good performance across all classes, not just high overall accuracy. The current model's inability to detect the neutral stance is a significant limitation that needs to be addressed before using it in any practical application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Model on New Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Climate change is a hoax perpetrated by scientists for grant money.\n",
      "Predicted stance: 2\n",
      "\n",
      "Text: We need urgent action to reduce carbon emissions and save our planet.\n",
      "Predicted stance: 2\n",
      "\n",
      "Text: The jury is still out on whether human activities are causing global warming.\n",
      "Predicted stance: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to predict stance for new text\n",
    "def predict_stance(text):\n",
    "    return stance_classifier.predict([text])[0]\n",
    "\n",
    "# Test the model on some example texts\n",
    "example_texts = [\n",
    "    \"Climate change is a hoax perpetrated by scientists for grant money.\",\n",
    "    \"We need urgent action to reduce carbon emissions and save our planet.\",\n",
    "    \"The jury is still out on whether human activities are causing global warming.\"\n",
    "]\n",
    "\n",
    "for text in example_texts:\n",
    "    stance = predict_stance(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted stance: {stance}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced model training completed.\n",
      "Balanced model saved successfully.\n",
      "Balanced Model Evaluation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.87      0.47       190\n",
      "           1       0.24      0.62      0.35        13\n",
      "           2       0.97      0.74      0.84      1410\n",
      "\n",
      "    accuracy                           0.75      1613\n",
      "   macro avg       0.51      0.74      0.55      1613\n",
      "weighted avg       0.89      0.75      0.79      1613\n",
      "\n",
      "\n",
      "Predictions with balanced model:\n",
      "Text: Climate change is a hoax perpetrated by scientists for grant money.\n",
      "Predicted stance: 2\n",
      "\n",
      "Text: We need urgent action to reduce carbon emissions and save our planet.\n",
      "Predicted stance: 0\n",
      "\n",
      "Text: The jury is still out on whether human activities are causing global warming.\n",
      "Predicted stance: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a pipeline with SMOTE, TF-IDF vectorizer, and Multinomial Naive Bayes classifier\n",
    "balanced_stance_classifier = ImbPipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "balanced_stance_classifier.fit(all_train_data['processed_text'], all_train_data['stance'])\n",
    "\n",
    "print(\"Balanced model training completed.\")\n",
    "\n",
    "# Save the model\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(balanced_stance_classifier, '../models/balanced_naive_bayes_stance_classifier.joblib')\n",
    "print(\"Balanced model saved successfully.\")\n",
    "\n",
    "# Evaluate the balanced model\n",
    "y_pred_balanced = balanced_stance_classifier.predict(test_data['processed_text'])\n",
    "\n",
    "# Generate the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "report_balanced = classification_report(test_data['stance'], y_pred_balanced)\n",
    "print(\"Balanced Model Evaluation Report:\")\n",
    "print(report_balanced)\n",
    "\n",
    "# Test the balanced model on example texts\n",
    "def predict_stance_balanced(text):\n",
    "    return balanced_stance_classifier.predict([text])[0]\n",
    "\n",
    "example_texts = [\n",
    "    \"Climate change is a hoax perpetrated by scientists for grant money.\",\n",
    "    \"We need urgent action to reduce carbon emissions and save our planet.\",\n",
    "    \"The jury is still out on whether human activities are causing global warming.\"\n",
    "]\n",
    "\n",
    "print(\"\\nPredictions with balanced model:\")\n",
    "for text in example_texts:\n",
    "    stance = predict_stance_balanced(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted stance: {stance}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model training completed.\n",
      "Logistic Regression model saved successfully.\n",
      "Logistic Regression Model Evaluation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       190\n",
      "           1       1.00      0.54      0.70        13\n",
      "           2       0.98      0.96      0.97      1410\n",
      "\n",
      "    accuracy                           0.95      1613\n",
      "   macro avg       0.91      0.78      0.82      1613\n",
      "weighted avg       0.95      0.95      0.95      1613\n",
      "\n",
      "\n",
      "Predictions with Logistic Regression model:\n",
      "Text: Climate change is a hoax perpetrated by scientists for grant money.\n",
      "Predicted stance: 2\n",
      "\n",
      "Text: We need urgent action to reduce carbon emissions and save our planet.\n",
      "Predicted stance: 0\n",
      "\n",
      "Text: The jury is still out on whether human activities are causing global warming.\n",
      "Predicted stance: 2\n",
      "\n",
      "Top 10 most important features:\n",
      "       feature  importance\n",
      "105     action    7.044596\n",
      "7191      real    4.594558\n",
      "7207    realli    4.267383\n",
      "8389   support    4.241476\n",
      "8636  threaten    3.283100\n",
      "8633    threat    3.199323\n",
      "7204    realiz    2.661995\n",
      "795     believ    2.614877\n",
      "7200   realiti    2.546381\n",
      "7912   serious    2.542499\n",
      "\n",
      "Bottom 10 least important features:\n",
      "              feature  importance\n",
      "1273    carbon offset   -0.876153\n",
      "6169           offset   -0.968402\n",
      "4497             hoax   -0.995829\n",
      "4237            graph   -1.038986\n",
      "2574            degre   -1.147837\n",
      "1683  climat alarmist   -1.185694\n",
      "3651             fake   -1.214141\n",
      "188            agenda   -1.410322\n",
      "7749             scam   -2.486270\n",
      "234          alarmist   -2.958761\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(all_train_data['stance']), y=all_train_data['stance'])\n",
    "class_weight_dict = dict(zip(np.unique(all_train_data['stance']), class_weights))\n",
    "\n",
    "# Create a pipeline with TF-IDF vectorizer and Logistic Regression classifier\n",
    "lr_stance_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 3))),\n",
    "    ('clf', LogisticRegression(class_weight=class_weight_dict, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "lr_stance_classifier.fit(all_train_data['processed_text'], all_train_data['stance'])\n",
    "\n",
    "print(\"Logistic Regression model training completed.\")\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(lr_stance_classifier, '../models/logistic_regression_stance_classifier.joblib')\n",
    "print(\"Logistic Regression model saved successfully.\")\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "y_pred_lr = lr_stance_classifier.predict(test_data['processed_text'])\n",
    "\n",
    "# Generate the classification report\n",
    "report_lr = classification_report(test_data['stance'], y_pred_lr)\n",
    "print(\"Logistic Regression Model Evaluation Report:\")\n",
    "print(report_lr)\n",
    "\n",
    "# Test the Logistic Regression model on example texts\n",
    "def predict_stance_lr(text):\n",
    "    return lr_stance_classifier.predict([text])[0]\n",
    "\n",
    "example_texts = [\n",
    "    \"Climate change is a hoax perpetrated by scientists for grant money.\",\n",
    "    \"We need urgent action to reduce carbon emissions and save our planet.\",\n",
    "    \"The jury is still out on whether human activities are causing global warming.\"\n",
    "]\n",
    "\n",
    "print(\"\\nPredictions with Logistic Regression model:\")\n",
    "for text in example_texts:\n",
    "    stance = predict_stance_lr(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted stance: {stance}\\n\")\n",
    "\n",
    "# Optional: Print feature importance\n",
    "tfidf = lr_stance_classifier.named_steps['tfidf']\n",
    "lr = lr_stance_classifier.named_steps['clf']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': tfidf.get_feature_names_out(),\n",
    "    'importance': lr.coef_[0]\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 most important features:\")\n",
    "print(feature_importance.head(10))\n",
    "print(\"\\nBottom 10 least important features:\")\n",
    "print(feature_importance.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Compute class weights\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m compute_class_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(all_train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstance\u001b[39m\u001b[38;5;124m'\u001b[39m]), y\u001b[38;5;241m=\u001b[39mall_train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstance\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m class_weight_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(all_train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstance\u001b[39m\u001b[38;5;124m'\u001b[39m]), class_weights))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Create individual classifiers\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(all_train_data['stance']), y=all_train_data['stance'])\n",
    "class_weight_dict = dict(zip(np.unique(all_train_data['stance']), class_weights))\n",
    "\n",
    "# Create individual classifiers\n",
    "lr = LogisticRegression(class_weight=class_weight_dict, max_iter=1000, C=0.1)  # Increased regularization\n",
    "nb = MultinomialNB()\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000)\n",
    "\n",
    "# Create the ensemble classifier\n",
    "ensemble_classifier = VotingClassifier(\n",
    "    estimators=[('lr', lr), ('nb', nb), ('nn', nn)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "stance_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 3))),\n",
    "    ('clf', ensemble_classifier)\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(stance_pipeline, all_train_data['processed_text'], all_train_data['stance'], cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Train the model on the full training set\n",
    "stance_pipeline.fit(all_train_data['processed_text'], all_train_data['stance'])\n",
    "\n",
    "print(\"Ensemble model training completed.\")\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(stance_pipeline, '../models/ensemble_stance_classifier.joblib')\n",
    "print(\"Ensemble model saved successfully.\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = stance_pipeline.predict(test_data['processed_text'])\n",
    "report = classification_report(test_data['stance'], y_pred)\n",
    "print(\"Ensemble Model Evaluation Report:\")\n",
    "print(report)\n",
    "\n",
    "# Test the model on example texts\n",
    "def predict_stance(text):\n",
    "    return stance_pipeline.predict([text])[0]\n",
    "\n",
    "example_texts = [\n",
    "    \"Climate change is a hoax perpetrated by scientists for grant money.\",\n",
    "    \"We need urgent action to reduce carbon emissions and save our planet.\",\n",
    "    \"The jury is still out on whether human activities are causing global warming.\"\n",
    "]\n",
    "\n",
    "print(\"\\nPredictions with Ensemble model:\")\n",
    "for text in example_texts:\n",
    "    stance = predict_stance(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted stance: {stance}\\n\")\n",
    "\n",
    "# Error analysis\n",
    "misclassified = test_data[y_pred != test_data['stance']]\n",
    "print(\"\\nSample of misclassified instances:\")\n",
    "print(misclassified[['processed_text', 'stance']].sample(min(5, len(misclassified))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_jupyter_env)",
   "language": "python",
   "name": "my_jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
